{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def segmentWords(s): \n",
    "    return s.split()\n",
    "\n",
    "def readFile(fileName):\n",
    "    # Function for reading file\n",
    "    # input: filename as string\n",
    "    # output: contents of file as list containing single words\n",
    "    contents = []\n",
    "    f = open(fileName)\n",
    "    for line in f:\n",
    "        contents.append(line)\n",
    "    f.close()\n",
    "    result = segmentWords('\\n'.join(contents))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Dataframe containing the counts of each word in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "\n",
    "for c in os.listdir(\"data_training\"):\n",
    "    directory = \"data_training/\" + c\n",
    "    for file in os.listdir(directory):\n",
    "        words = readFile(directory + \"/\" + file)\n",
    "        e = {x:words.count(x) for x in words}\n",
    "       # e['__FileID__'] = file\n",
    "        val = -1\n",
    "        if directory == 'data_training/pos':\n",
    "            val = 1\n",
    "        elif directory == 'data_training/neg':\n",
    "            val = 0\n",
    "        e['__CLASS__'] = val\n",
    "        d.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe from d - make sure to fill all the nan values with zeros.\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 45672)\n",
      "447\n",
      "0\n",
      "                 \u0005       \u0013earth     \u0013goodies          \u0013if      \u0013ripley  \\\n",
      "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
      "mean      0.000625     0.000625     0.000625     0.000625     0.000625   \n",
      "std       0.025000     0.025000     0.025000     0.025000     0.025000   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "          \u0013suspend        \u0013they      \u0013white\u0014            \u0014           \u0016  \\\n",
      "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.00000   \n",
      "mean      0.000625     0.000625     0.000625     0.003125     0.00750   \n",
      "std       0.025000     0.025000     0.025000     0.074958     0.25492   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
      "max       1.000000     1.000000     1.000000     2.000000    10.00000   \n",
      "\n",
      "          ...          zukovsky      zundel       zurg's      zweibel  \\\n",
      "count     ...       1600.000000  1600.00000  1600.000000  1600.000000   \n",
      "mean      ...          0.000625     0.00125     0.000625     0.000625   \n",
      "std       ...          0.025000     0.05000     0.025000     0.025000   \n",
      "min       ...          0.000000     0.00000     0.000000     0.000000   \n",
      "25%       ...          0.000000     0.00000     0.000000     0.000000   \n",
      "50%       ...          0.000000     0.00000     0.000000     0.000000   \n",
      "75%       ...          0.000000     0.00000     0.000000     0.000000   \n",
      "max       ...          1.000000     2.00000     1.000000     1.000000   \n",
      "\n",
      "             zwick      zwick's    zwigoff's        zycie       zycie'  \\\n",
      "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
      "mean      0.005625     0.002500     0.001250     0.000625     0.000625   \n",
      "std       0.119801     0.061205     0.035344     0.025000     0.025000   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       3.000000     2.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "                 |  \n",
      "count  1600.000000  \n",
      "mean      0.001250  \n",
      "std       0.035344  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       0.000000  \n",
      "75%       0.000000  \n",
      "max       1.000000  \n",
      "\n",
      "[8 rows x 45672 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data=d)\n",
    "# Just to prove that there are some numbers in the dataset\n",
    "print(df.shape)\n",
    "print(sum(pd.isnull(df[\"they\"])))\n",
    "df = df.replace('NaN', 0)\n",
    "\n",
    "sm = 0\n",
    "for index, row in df.iterrows():\n",
    "    sm += sum(pd.isnull(row))\n",
    "    \n",
    "print(sm)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Sample 80% of your dataframe to be the training data\n",
    "\n",
    "* Let the remaining 20% be the validation data (you can filter out the indicies of the original dataframe that weren't selected for the training data)\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1280, 45672), (320, 45672))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/porrster/home/porrster/Documents/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "def shuffleAndSplit(data):\n",
    "    length = .8 * data.shape[0]\n",
    "    indices = np.arange(data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return (data.iloc[indices[:length]], data.iloc[indices[length:]])\n",
    "\n",
    "#Shuffle original dataframe and split into test\n",
    "# and validation sets\n",
    "dfTest, dfVal = shuffleAndSplit(df)\n",
    "dfTest = pd.DataFrame(data=dfTest)\n",
    "dfVal = pd.DataFrame(data=dfVal)\n",
    "print(dfTest.shape, dfVal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the dataframe for both training and validation data into x and y dataframes - where y contains the labels and x contains the words\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1280, 45671), (1280,))\n",
      "((320, 45671), (320,))\n"
     ]
    }
   ],
   "source": [
    "#Test data and labels\n",
    "testData = dfTest.drop('__CLASS__', axis=1)\n",
    "testLabels = dfTest['__CLASS__']\n",
    "print(testData.shape, testLabels.shape)\n",
    "#Validation datasets\n",
    "valData = dfVal.drop('__CLASS__', axis=1)\n",
    "valLabels = dfVal['__CLASS__']\n",
    "print(valData.shape, valLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Logistic Regression\n",
    "* Use sklearn's linear_model.LogisticRegression() to create your model.\n",
    "* Fit the data and labels with your model.\n",
    "* Score your model with the same data and labels.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8625\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(penalty='l2')\n",
    "model.fit(testData, testLabels)\n",
    "print(model.score(valData, valLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85625\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "#Lets adjust C for more regularization\n",
    "model = LogisticRegression(penalty='l2', C=3)\n",
    "model.fit(testData, testLabels)\n",
    "print(model.score(valData, valLabels))\n",
    "model = LogisticRegression(penalty='l2', C=8)\n",
    "model.fit(testData, testLabels)\n",
    "print(model.score(valData, valLabels))\n",
    "#We can see that adding a regularization term does not seem to help\n",
    "# increase accuracy slightly, indicating that the inaccuracy\n",
    "# was not caused by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "* In the backward stepsize selection method, you can remove coefficients and the corresponding x columns, where the coefficient is more than a particular amount away from the mean - you can choose how far from the mean is reasonable.\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.where.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.std.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.mean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45671\n",
      "25036\n"
     ]
    }
   ],
   "source": [
    "weights = model.coef_[0]\n",
    "total = sum(weights)\n",
    "print(len(weights))\n",
    "norm = np.asarray(weights) / total\n",
    "bad = [x for x in range(len(norm)) if norm[x] < .00000001]\n",
    "print(len(bad))\n",
    "\n",
    "f = open('/home/porrster/Data-Science-Decal-Fall-2017/Assignments/Project2_DSDFa17/badcols', 'w')\n",
    "\n",
    "model = LogisticRegression(penalty='l2', C=8)\n",
    "model.fit(testData, testLabels)\n",
    "errBase = model.score(valData, valLabels)\n",
    "cols = testData.columns\n",
    "batchsize = int(len(bad) * .01)\n",
    "for i in range(len(bad) // batchsize):\n",
    "    testData0 = testData.drop(cols[(i*batchsize):((i+1)*batchsize)], axis=1)\n",
    "    valData0 = valData.drop(cols[(i*batchsize):((i+1)*batchsize)], axis=1)\n",
    "    model.fit(testData0, testLabels)\n",
    "    err = model.score(valData0, valLabels)\n",
    "    if errBase <= err:\n",
    "        for count in range(batchsize):\n",
    "            ind = (i * batchsize) + count\n",
    "            testData0 = testData.drop(cols[ind], axis=1)\n",
    "            valData0 = valData.drop(cols[ind], axis=1)\n",
    "            model.fit(testData0, testLabels)\n",
    "            err = model.score(valData0, valLabels)\n",
    "            if errBase <= err:\n",
    "                testData = testData0\n",
    "                valData = valData0\n",
    "    print(i)\n",
    "for i in range(len(bad) - (len(bad) // batchsize) * 100):\n",
    "    testData0 = testData.drop(cols[(i*batchsize):((i+1)*batchsize)], axis=1)\n",
    "    valData0 = valData.drop(cols[(i*batchsize):((i+1)*batchsize)], axis=1)\n",
    "    model.fit(testData0, testLabels)\n",
    "    err = model.score(valData0, valLabels)\n",
    "    if errBase <= err:\n",
    "        testData = testData0\n",
    "        valData = valData0\n",
    "f.write(testdata.columns)\n",
    "f.close()\n",
    "print(len(testData))    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did you select which features to remove? Why did that reduce overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1280, 24503), (1280,))\n",
      "0.821875\n"
     ]
    }
   ],
   "source": [
    "cols = testData.columns\n",
    "#keepCols = [cols[x] for x in keep]\n",
    "#testDataClean = testData[keepCols[:]]\n",
    "#valDataClean = valData[keepCols[:]]\n",
    "\n",
    "print(testData.shape, testLabels.shape)\n",
    "model = LogisticRegression(penalty='l2', C=1)\n",
    "model.fit(testData, testLabels)\n",
    "print(model.score(valData, valLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Decision Tree\n",
    "\n",
    "* Initialize your model as a decision tree with sklearn.\n",
    "* Fit the data and labels to the model.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters\n",
    "* To test out which value is optimal for a particular parameter, you can either loop through various values or look into sklearn.model_selection.GridSearchCV\n",
    "\n",
    "References:\n",
    "\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did you choose which parameters to change and what value to give to them? Feel free to show a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is a single decision tree so prone to overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Random Forest\n",
    "\n",
    "* Use sklearn's ensemble.RandomForestClassifier() to create your model.\n",
    "* Fit the data and labels with your model.\n",
    "* Score your model with the same data and labels.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What parameters did you choose to change and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does a random forest classifier prevent overfitting better than a single decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
