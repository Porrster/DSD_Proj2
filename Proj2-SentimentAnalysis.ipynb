{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segmentWords(s): \n",
    "    return s.split()\n",
    "\n",
    "def readFile(fileName):\n",
    "    # Function for reading file\n",
    "    # input: filename as string\n",
    "    # output: contents of file as list containing single words\n",
    "    contents = []\n",
    "    f = open(fileName)\n",
    "    for line in f:\n",
    "        contents.append(line)\n",
    "    f.close()\n",
    "    result = segmentWords('\\n'.join(contents))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Dataframe containing the counts of each word in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "\n",
    "for c in os.listdir(\"data_training\"):\n",
    "    directory = \"data_training/\" + c\n",
    "    for file in os.listdir(directory):\n",
    "        words = readFile(directory + \"/\" + file)\n",
    "        e = {x:words.count(x) for x in words}\n",
    "        val = -1\n",
    "        if directory == 'data_training/pos':\n",
    "            val = 1\n",
    "        elif directory == 'data_training/neg':\n",
    "            val = 0\n",
    "        e['__CLASS__'] = val\n",
    "        d.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe from d - make sure to fill all the nan values with zeros.\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 45672)\n",
      "447\n",
      "0\n",
      "                 \u0005       \u0013earth     \u0013goodies          \u0013if      \u0013ripley  \\\n",
      "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
      "mean      0.000625     0.000625     0.000625     0.000625     0.000625   \n",
      "std       0.025000     0.025000     0.025000     0.025000     0.025000   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "          \u0013suspend        \u0013they      \u0013white\u0014            \u0014           \u0016  \\\n",
      "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.00000   \n",
      "mean      0.000625     0.000625     0.000625     0.003125     0.00750   \n",
      "std       0.025000     0.025000     0.025000     0.074958     0.25492   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
      "max       1.000000     1.000000     1.000000     2.000000    10.00000   \n",
      "\n",
      "          ...          zukovsky      zundel       zurg's      zweibel  \\\n",
      "count     ...       1600.000000  1600.00000  1600.000000  1600.000000   \n",
      "mean      ...          0.000625     0.00125     0.000625     0.000625   \n",
      "std       ...          0.025000     0.05000     0.025000     0.025000   \n",
      "min       ...          0.000000     0.00000     0.000000     0.000000   \n",
      "25%       ...          0.000000     0.00000     0.000000     0.000000   \n",
      "50%       ...          0.000000     0.00000     0.000000     0.000000   \n",
      "75%       ...          0.000000     0.00000     0.000000     0.000000   \n",
      "max       ...          1.000000     2.00000     1.000000     1.000000   \n",
      "\n",
      "             zwick      zwick's    zwigoff's        zycie       zycie'  \\\n",
      "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
      "mean      0.005625     0.002500     0.001250     0.000625     0.000625   \n",
      "std       0.119801     0.061205     0.035344     0.025000     0.025000   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       3.000000     2.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "                 |  \n",
      "count  1600.000000  \n",
      "mean      0.001250  \n",
      "std       0.035344  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       0.000000  \n",
      "75%       0.000000  \n",
      "max       1.000000  \n",
      "\n",
      "[8 rows x 45672 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data=d)\n",
    "# Just to prove that there are some numbers in the dataset\n",
    "print(df.shape)\n",
    "print(sum(pd.isnull(df[\"they\"])))\n",
    "df = df.replace('NaN', 0)\n",
    "\n",
    "sm = 0\n",
    "for index, row in df.iterrows():\n",
    "    sm += sum(pd.isnull(row))\n",
    "    \n",
    "print(sm)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Sample 80% of your dataframe to be the training data\n",
    "\n",
    "* Let the remaining 20% be the validation data (you can filter out the indicies of the original dataframe that weren't selected for the training data)\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1280, 45672), (320, 45672))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/porrster/home/porrster/Documents/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "def shuffleAndSplit(data):\n",
    "    length = .8 * data.shape[0]\n",
    "    indices = np.arange(data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return (data.iloc[indices[:length]], data.iloc[indices[length:]])\n",
    "\n",
    "#Shuffle original dataframe and split into test\n",
    "# and validation sets\n",
    "dfTest, dfVal = shuffleAndSplit(df)\n",
    "print(dfTest.shape, dfVal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the dataframe for both training and validation data into x and y dataframes - where y contains the labels and x contains the words\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1280, 45671), (1280,))\n",
      "((320, 45671), (320,))\n"
     ]
    }
   ],
   "source": [
    "#Test data and labels\n",
    "testData = dfTest.drop('__CLASS__', axis=1)\n",
    "testLabels = dfTest['__CLASS__']\n",
    "print(testData.shape, testLabels.shape)\n",
    "#Validation datasets\n",
    "valData = dfVal.drop('__CLASS__', axis=1)\n",
    "valLabels = dfVal['__CLASS__']\n",
    "print(valData.shape, valLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Logistic Regression\n",
    "* Use sklearn's linear_model.LogisticRegression() to create your model.\n",
    "* Fit the data and labels with your model.\n",
    "* Score your model with the same data and labels.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80625\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(penalty='l2')\n",
    "model.fit(testData, testLabels)\n",
    "print(model.score(valData, valLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80625\n",
      "0.80625\n"
     ]
    }
   ],
   "source": [
    "#Lets adjust C for more regularization\n",
    "model = LogisticRegression(penalty='l2', C=3)\n",
    "model.fit(testData, testLabels)\n",
    "print(model.score(valData, valLabels))\n",
    "model = LogisticRegression(penalty='l2', C=8)\n",
    "model.fit(testData, testLabels)\n",
    "print(model.score(valData, valLabels))\n",
    "#We can see that adding a regularization term does not seem to help\n",
    "# increase accuracy slightly, indicating that the inaccuracy\n",
    "# was not caused by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "* In the backward stepsize selection method, you can remove coefficients and the corresponding x columns, where the coefficient is more than a particular amount away from the mean - you can choose how far from the mean is reasonable.\n",
    "\n",
    "References:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.where.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.std.html\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.mean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backwardsStepwiseFeatureElimination(testData, testLabels, valData, valLabels, bad=-1):\n",
    "    if bad == -1:\n",
    "        bad = testData\n",
    "    model = LogisticRegression(penalty='l2', C=8)\n",
    "    model.fit(testData, testLabels)\n",
    "    errBase = model.score(valData, valLabels)\n",
    "    cols = testData.columns\n",
    "    batchsize = int(len(bad) * .01)\n",
    "    for i in range(len(bad) // batchsize):\n",
    "        testData0 = testData.drop(cols[bad[(i*batchsize):((i+1)*batchsize)]], axis=1)\n",
    "        valData0 = valData.drop(cols[bad[(i*batchsize):((i+1)*batchsize)]], axis=1)\n",
    "        model.fit(testData0, testLabels)\n",
    "        err = model.score(valData0, valLabels)\n",
    "        if errBase < err:\n",
    "            for count in range(batchsize):\n",
    "                ind = (i * batchsize) + count\n",
    "                testData0 = testData.drop(cols[ind], axis=1)\n",
    "                valData0 = valData.drop(cols[ind], axis=1)\n",
    "                model.fit(testData0, testLabels)\n",
    "                err = model.score(valData0, valLabels)\n",
    "                if errBase <= err:\n",
    "                    testData = testData0\n",
    "                    valData = valData0\n",
    "                    errBase = err\n",
    "        print(i)\n",
    "    print(errBase)\n",
    "    return testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45671\n",
      "26968\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "weights = model.coef_[0]\n",
    "total = sum(weights)\n",
    "print(len(weights))\n",
    "norm = np.asarray(weights) / total\n",
    "badCols = [x for x in range(len(norm)) if norm[x] < .00001]\n",
    "print(len(badCols))\n",
    "f = open('/home/porrster/Data-Science-Decal-Fall-2017/Assignments/Project2_DSDFa17/badcols', 'w')\n",
    "#Run backwards stepwise feature elimination\n",
    "testData = backwardsStepwiseFeatureElimination(testData, testLabels, valData, valLabels, badCols)\n",
    "#Write columns we keep to file so we dont need to always run that long function\n",
    "for item in testData.columns:\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.close()\n",
    "print(len(testData))    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did you select which features to remove? Why did that reduce overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = testData.columns\n",
    "#keepCols = [cols[x] for x in keep]\n",
    "#testDataClean = testData[keepCols[:]]\n",
    "#valDataClean = valData[keepCols[:]]\n",
    "#Confirm that feature elimination improved results\n",
    "print(testData.shape, testLabels.shape)\n",
    "model = LogisticRegression(penalty='l2', C=8)\n",
    "model.fit(testData, testLabels)\n",
    "print(model.score(valData, valLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Decision Tree\n",
    "\n",
    "* Initialize your model as a decision tree with sklearn.\n",
    "* Fit the data and labels to the model.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion='entropy', max_depth=100, max_leaf_nodes=500)\n",
    "\n",
    "classifier.fit(testData, testLabels)\n",
    "classifier.score(valData, valLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters\n",
    "* To test out which value is optimal for a particular parameter, you can either loop through various values or look into sklearn.model_selection.GridSearchCV\n",
    "\n",
    "References:\n",
    "\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select hyperparameters to test\n",
    "max_depths = [10, 20, 30, 50, 75, 100]\n",
    "leaf_nodes = [20, 40, 60, 100, 150, 200, 300, 500]\n",
    "scores = []\n",
    "# For each value of the hyperparameters, train and score a model.\n",
    "for i in range(len(max_depths)):\n",
    "    scores.append([])\n",
    "    for j in  range(len(leaf_nodes)):\n",
    "        temp_classifier = DecisionTreeClassifier(criterion='entropy', \n",
    "                                            max_depth=max_depths[i], max_leaf_nodes=leaf_nodes[j])\n",
    "        temp_classifier.fit(testData, testLabels)\n",
    "        \n",
    "        scores[i].append(temp_classifier.score(valData, valLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did you choose which parameters to change and what value to give to them? Feel free to show a plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to explore the number of leaf nodes and the maximum depth of the tree. The two are intrinsically related but offer some interesting interplay. The number of leaf nodes was particularly interesting, as increasing the number of leaf nodes led certainly to lower validation accuracy. We hypothesize this is due to overfitting, since the tree will split too many times outside of what is strictly necessary and instead overfit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(scores)):\n",
    "    for j in range(len(scores[i])):\n",
    "        print(round(scores[i][j], 4), end='  ')\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Best score is 0.6625, multiple sets of hyperparameters hit this maximum in the dataset.\n",
    "# Notably when the number of leaf nodes is small, likely prevents overfitting.\n",
    "# Perhaps there is something better, but based on these results it will not be by much.\n",
    "# And is going to be very hard to find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is a single decision tree so prone to overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single decision tree overfits on its training data because it grows organically from its inputs and forms a rigid structure around it. Particularly in this dataset, the decision tree gets a overwhelming amount of features and has a lot of trouble sorting out the useful ones from the noise. One possible thing to explore is limiting max_features, making sure that not too many features are considered at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using best hyperparameters from last part\n",
    "\n",
    "for i in range(1, 101, 10):\n",
    "    limited_classifier = DecisionTreeClassifier(criterion='entropy', \n",
    "                                                max_depth=10, max_leaf_nodes=100, max_features=i)\n",
    "\n",
    "    limited_classifier.fit(testData, testLabels)\n",
    "\n",
    "    print(limited_classifier.score(valData, valLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing max_features, contrary to what we expected, did not improve validation accuracy. We could venture the hypothesis that the tree is not in fact overfitting, but rather failing to adequately capture the data in a meaningful way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Random Forest\n",
    "\n",
    "* Use sklearn's ensemble.RandomForestClassifier() to create your model.\n",
    "* Fit the data and labels with your model.\n",
    "* Score your model with the same data and labels.\n",
    "\n",
    "References:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=10, criterion='entropy', max_features='auto',\n",
    "                                    max_depth=100, max_leaf_nodes=500, bootstrap=True)\n",
    "\n",
    "forest.fit(testData, testLabels)\n",
    "forest.score(valData, valLabels)\n",
    "\n",
    "# Clearly, our forest isn't that much better than our decision tree in this state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's first check how changing the number of trees affects the score\n",
    "\n",
    "for i in range(10):\n",
    "    temp_forest = RandomForestClassifier(n_estimators=10*i + 1, criterion='entropy', max_features='auto',\n",
    "                                    max_depth=100, max_leaf_nodes=500, bootstrap=True)\n",
    "    forest.fit(testData, testLabels)\n",
    "    print(forest.score(valData, valLabels))\n",
    "    \n",
    "# Having a high number of estimators doesn't seem particularly useful, let's go with 20 as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select hyperparameters to test\n",
    "max_depths = [10, 20, 30, 50, 75, 100]\n",
    "leaf_nodes = [20, 40, 60, 100, 150, 200, 300, 500]\n",
    "scores = []\n",
    "# For each value of the hyperparameters, train and score a model.\n",
    "for i in range(len(max_depths)):\n",
    "    scores.append([])\n",
    "    for j in  range(len(leaf_nodes)):\n",
    "        temp_forest = RandomForestClassifier(n_estimators=20, criterion='entropy', max_features='auto',\n",
    "                                    max_depth=max_depths[i], max_leaf_nodes=leaf_nodes[j], bootstrap=True)\n",
    "        temp_forest.fit(testData, testLabels)\n",
    "        scores[i].append(temp_forest.score(valData, valLabels))\n",
    "\n",
    "for i in range(len(scores)):\n",
    "    print(scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in range(0, 30, 5):\n",
    "    print(testRandomForest(n_estimators=20, criterion='entropy', max_features='auto',\n",
    "                                    max_depth=30+t, max_leaf_nodes=100, bootstrap=True))\n",
    "    \n",
    "# Note that the general trend is rising, even if the randomness in the forest selection \n",
    "#  smudges the effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"With bootstrap, the validation accuracy is:\") \n",
    "print(testRandomForest(n_estimators=20, criterion='entropy', max_features='auto',\n",
    "                                    max_depth=30, max_leaf_nodes=100, bootstrap=True, trials=20))\n",
    "print(\"Without bootstrap, the validation accuracy is:\")\n",
    "print(testRandomForest(n_estimators=20, criterion='entropy', max_features='auto',\n",
    "                                    max_depth=30, max_leaf_nodes=100, bootstrap=False, trials=20))\n",
    "\n",
    "# Strangely, removing bootstrap decreases validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What parameters did you choose to change and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We first chose to play around with n_estimators. It seems like very large numbers of trees in the forest doesn't lead to greatly improved results. Messing around with max_depth and max_leaf_nodes shows that unlike in the regular forests, increasing the depth of the tree does not decrease the validation accuracy. We would guess that this is due to the random nature of the forest: there is no room for overfitting because any overfitted regions of any one tree will be averaged out over the whole forest. One thing we found that was very interesting was that removing bootstrap increases the validation accuracy on average. We have a couple hypotheses for this, but one proposed cause is that our reviews don't tend to center around a mean, since language is such a diverse and variant thing. The most common words are also the words most devoid of positivity and negativity, and the spread of positive and negative words used keep there from being a well defined central tendency that bootstrapping would enhance. Instead, emphasizing the random selection of features forces us to look at different words and make decisions on them, which gives us more perspectives on the words in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does a random forest classifier prevent overfitting better than a single decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Because a random forest doesn't limit itself to a single section of the dataset, it is less prone to making decision errors on certain splits. The splits are chosen randomly so not every tree encounters the same splits, and as a result, certain splits that misrepresent the actual dataset by overfitting to the training data are averaged out of the system ahead of time. Training in ensemble, then, gives us better results since we can ignore the particular errors in splitting of a single decision tree (equivalent to asking too specific a question in 20 questions), and instead let the groupthink of the random forest make the right decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
